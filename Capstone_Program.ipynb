{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for the Capstone Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Capstone Project Course\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "print('Hello Capstone Project Course')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction/Business Problem \n",
    "\n",
    "- Business Problem: \n",
    "    - Accidents continue to block traffic and cause backups in the greater Seattle area.  In order to help alleviate the congestion during peak hours of travel we need to know what causes them in the first place.  \n",
    "\n",
    "\n",
    "- Hypothesis/Thoughts: \n",
    "    - The date/time of day effects the amount of accidents that will occur\n",
    "        - Independent Variable: Date/Time\n",
    "    - The severity of an accident is determened by location and time\n",
    "        - Independent Variable: Locaiton & Time\n",
    "    \n",
    "    \n",
    "    New Hypothesis after extensive data exploration: Road Conditions are the influence in the severity of the accident when all things are equal; i.e. not considering drugs/alcohol etc. \n",
    "\n",
    "\n",
    "- Data Background: \n",
    "    - SDOT (Seattle Department of Transportation) Data \n",
    "    - Removed 5,639 of the 194,673 rows in the initial data set that were noted NEI (Not enough Information or Insufficient Location Information)\n",
    "    - Data can be found via GitHub URL with the metadata descriptions.  \n",
    "    - Date Time cannot be used to predict severity due to the inconsistency of the data entered\n",
    "    - Severity Code & Severity Code Definitions:\n",
    "        - 0: Little to no Probability (Clear Conditions)\n",
    "        - 1: Very Low Probability — Chance or Property Damage\n",
    "        - 2: Low Probability — Chance of Injury\n",
    "        - 3: Mild Probability — Chance of Serious Injury\n",
    "        - 4: High Probability — Chance of Fatality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SDOT_Collisions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Unique Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SEVERITYCODE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['WEATHER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ROADCOND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LIGHTCOND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SPEEDING'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evening the sample size out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_major = data[data.SEVERITYCODE == 1]\n",
    "df_minor = data[data.SEVERITYCODE == 2]\n",
    "\n",
    "df_smpl = resample(df_major, replace=False, n_samples = 19576, random_state=123)\n",
    "df = pd.concat([df_smpl,df_minor])\n",
    "\n",
    "df['SEVERITYCODE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting fields to category then labeling  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({\"WEATHER\":'category', \"ROADCOND\":'category', \"LIGHTCOND\":'category'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"WEATHER_c\"] = df[\"WEATHER\"].cat.codes\n",
    "df[\"ROADCOND_c\"] = df[\"ROADCOND\"].cat.codes\n",
    "df[\"LIGHTCOND_c\"] = df[\"LIGHTCOND\"].cat.codes\n",
    "Feature = df[['WEATHER','ROADCOND','LIGHTCOND','WEATHER_c','ROADCOND_c','LIGHTCOND_c']]\n",
    "X = np.asarray(Feature[['WEATHER_c','ROADCOND_c','LIGHTCOND_c']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['SEVERITYCODE'].values\n",
    "y[0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building The Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print('Test set shape: ', X_test.shape, y_test.shape)\n",
    "print('Training set shape: ', X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbor(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k = 20\n",
    "#Train Model and Predict  \n",
    "neigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
    "neigh_pred = neigh.predict(X_test)\n",
    "neigh_pred[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, jaccard_similarity_score, log_loss\n",
    "print('KNN F1-Score: ', f1_score(y_test, neigh_pred, average='macro'))\n",
    "print('KNN Jaccard Score: ', jaccard_similarity_score(y_test, neigh_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine (SVM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "y_train = y_train.astype(float)\n",
    "s_svm = svm.LinearSVC(random_state=7)\n",
    "s_svm.fit(X_train, y_train)  \n",
    "\n",
    "y_pred=s_svm.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVM F1-Score is: ',f1_score(y_train, y_pred, average='weighted'))\n",
    "print('SVM Jaccard Score is: ',jaccard_similarity_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion='entropy',max_depth = 6)\n",
    "tree.fit(X_train, y_train)\n",
    "ptree = tree.predict(X_test)\n",
    "ptree[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Decision Tree F1-Score: ', f1_score(y_test, ptree, average='macro'))\n",
    "print('Decision Tree Jaccard Score: ', jaccard_similarity_score(y_test,ptree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train, y_train)\n",
    "LRPe = LR.predict(X_test)\n",
    "LRP = LR.predict_proba(X_test)\n",
    "LRPe[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Logistic Regression F1-Score is: ', f1_score(y_test, LRPe, average='macro'))\n",
    "print('Logistic Regression Jaccard Score is: ', jaccard_similarity_score(y_test, LRPe))\n",
    "print('Logistic Regression LogLoss is: ', log_loss(y_test, LRP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Reds):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, LRPe, labels=[1,2])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['SEVERITY=1','SEVERITY=2'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, LRPe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1-Scores\n",
    "print('KNN F1-Score: ', f1_score(y_test, neigh_pred, average='macro'))\n",
    "print('Decision Tree F1-Score: ', f1_score(y_test, ptree, average='macro'))\n",
    "print('Logistic Regression F1-Score is: ', f1_score(y_test, LRPe, average='macro'))\n",
    "print('SVM F1-Score is: ',f1_score(y_train, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccard Scores \n",
    "print('KNN Jaccard Score: ', jaccard_similarity_score(y_test, neigh_pred))\n",
    "print('Decision Tree Jaccard Score: ', jaccard_similarity_score(y_test,ptree))\n",
    "print('Logistic Regression Jaccard Score is: ', jaccard_similarity_score(y_test, LRPe))\n",
    "print('SVM Jaccard Score is: ',jaccard_similarity_score(y_train, y_pred),'\\n')\n",
    "# Log Loss Score\n",
    "print('Logistic Regression LogLoss is: ', log_loss(y_test, LRP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based off of the testing done, the decision tree is the best model to test the data with.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings - After testing the historical data provided by Seattle Departement of Transportation, we were not able to find if the time of day played a factor in the severity of an accident due to the data that was entered.  However, we did find that weather, light and road conditions have an impact on the severity of an accident; either class 1 - Property Damage or class 2 - Injury.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
